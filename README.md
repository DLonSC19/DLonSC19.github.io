![TCHPC](https://tc.computer.org/tchpc/wp-content/uploads/sites/3/2017/06/tchpc_logo_cmyk.png){:width="300px"}
![SC19](https://sc19.supercomputing.org/app/uploads/2018/11/ogimage_1200.png){:width="300px"}

### Please sign up [the DLS mail list](https://forms.gle/cMEKocLE8vcu2juZ9)

### Program (Nov 17th, 9AM--5:30PM, Location: [502-503-504](https://sc19.supercomputing.org/map/?location=r502-503-504)

| Time | Title | Speaker |
| --- | --- | --- |
| 9:00--9:05 | Opening | Ian T. Foster, UChicago and ANL |
| 9:05--10:00 | Keynote: AI for HPC and HPC for AI: Bidirectional Convergence Efforts of  HPC and AI on the Fugaku Supercomputer | Satoshi Matsuoka, Tokyo Institute of Technology |
| 10:00--10:30 | Morning Break | |
| 10:30--10:55 | DeepDriveMD: Deep-Learning Driven Adaptive Molecular Simulations for Protein Folding |  Arvind Ramanathan, ANL |
| 10:55--11:20 | Deep Facial Recognition using Tensorflow | Chris A. Mattmann, JPL and USC |
| 11:20--11:45 | Deep Learning Accelerated Light Source Experiments | Zhengchun Liu, ANL |
| 11:45--12:10 | DC-S3GD: Delay-Compensated Stale-Synchronous SGD for Large-Scale Decentralized Neural Network Training |Alessandro Rigazzi, Cray|
| 12:10--12:30 | Aggregating Local Storage for Scalable Deep Learning I/O | Zhao Zhang, TACC |
| 12:30--14:00 | Lunch Break | |
| 14:00--14:30 | Highly-scalable, physics-informed GANs for learning solutions of stochastic PDEs | Thorsten Kurth , LBNL |
| 14:30--15:00 | Deep Learning for Gap Crossing Ability of Ground Vehicles | Benjamin Parsons, USACE-ERDC |
| 15:00--15:30 | Afternoon Break | |
| 15:30--16:00 | Scaling Distributed Training of Flood-Filling Networks on HPC Infrastructure for Brain Mapping | Wushi Dong, UChicago |
| 16:00--16:30 | Evolving larger convolutional layer kernel sizes for a settlement detection deep-learner on Summit | Mark Coletti, ORNL |
| 16:30--17:00 | Scaling TensorFlow, PyTorch, and MXNet using MVAPICH2 for High-Performance Deep Learning on Frontera | Arpan Jain, OSU |
| 17:00--17:30 | Strategies to Deploy and Scale Deep Learning on the Summit Supercomputer | Junqi Yin, ORNL|


The Deep Learning (DL) on Supercomputers workshop (In cooperation with TCHPC and held in conjunction with SC19: The International Conference for High Performance Computing, Networking, Storage and Analysis) will be in Denver, CO, on Nov 17th, 2019. 
This third workshop in the Deep Learning on Supercomputers series provides a forum for practitioners working on any and all aspects of DL for scientific research in the High Performance Computing (HPC) context to present their latest research results. The general theme of this workshop series is the intersection of DL and HPC. Its scope encompasses application development in scientific scenarios using HPC platforms; DL methods applied to numerical simulation; fundamental algorithms, enhanced procedures, and software development methods to enable scalable training and inference; hardware changes with impact on future supercomputer design; and machine deployment, performance evaluation, and reproducibility practices for DL applications, with an emphasis on scientific usage.


Topics include but are not limited to:
- Emerging scientific applications driven by DL methods
- Novel interactions between DL and traditional numerical simulation
- Effectiveness and limitations of DL methods in scientific research
- Algorithms and procedures to enhance reproducibility of scientific DL applications
- Data management through the life cycle of scientific DL applications
- General algorithms and procedures for efficient and scalable DL training
- General algorithms and systems for large scale model serving for scientific use cases
- New software, and enhancements to existing software, for scalable DL
- DL communication optimization at scale
- I/O optimization for DL at scale
- Hardware (processors, accelerators, memory hierarchy, interconnect) changes with impact on deep learning in the HPC context
- DL performance evaluation and analysis on deployed systems
- DL performance modeling and tuning of DL on supercomputers
- DL benchmarks on supercomputers

As part of the reproducibility initiative, the workshop requires authors to provide information such as the algorithms, software releases, datasets, and hardware configurations used. For performance evaluation studies, we will encourage authors to use well-known benchmarks or applications with open accessible datasets: for example, [MLPerf](https://github.com/mlperf/training) and ResNet-50 with the [ImageNet-1K dataset](http://www.image-net.org/archive/stanford/fall11_whole.tar).

For questions, please contact (DLSuperWorkshop19@gmail.com).
<!--- You can use the [editor on GitHub](https://github.com/DLonSC/DLonSC.github.io/edit/master/README.md) to maintain and preview the content for your website in Markdown files. -->

<!--- Whenever you commit to this repository, GitHub Pages will run [Jekyll](https://jekyllrb.com/) to rebuild the pages in your site, from the content in your Markdown files. -->

### Import Dates (New with extension)

- Papers due: ~~Sep 1st, 2019~~ ~~Sep 11th, 2019~~ Sep 16th, 2019
- Acceptance notification: ~~Sep 16th, 2019~~ ~~Sep 26th, 2019~~ ~~Oct 1st, 2019~~ Oct 3rd, 2019
- Camera ready: ~~Oct 1st, 2019~~ Oct 11th, 2019
- Workshop date: Nov 17th, 2019

### Paper Submission

Authors are invited to submit unpublished, original work with a minimum of 6 and a maximum of 8 pages (excluding references) in [IEEE conference format ](https://www.ieee.org/conferences/publishing/templates.html) and submitted using [Linklings (login required)](https://submissions.supercomputing.org/?page=Submit&id=SC19WorkshopDeepLearningonSupercomputersSubmission&site=sc19). IEEE TCHPC conditionally agrees to publish accepted papers.



### Organizing Committee
- Valeriu Codreanu (co-chair), SURFsara, Netherlands
- Ian Foster (co-chair), UChicago & ANL, USA
- Zhao Zhang (co-chair), TACC, USA
- Weijia Xu (proceeding chair), TACC, USA
- Ahmed Al-Jarro, Fujitsu Laboratories of Europe, UK
- Takuya Akiba, Preferred Networks, Japan
- Thomas S. Brettin, ANL, USA
- Nikoli Dryden, ETH, Switzerland
- Erich Elsen, DeepMind, USA
- Steve Farrell, LBNL, USA
- Song Feng, IBM Research, USA
- Boris Ginsburg, Nvidia, USA
- Torsten Hoefler, ETH, Switzerland
- Jessy Li, UT Austin, USA
- Zhengchun Liu, ANL, USA
- Chris A. Mattmann, JPL, Caltech & USC, USA
- Peter Messmer, Nvidia, USA
- Damian Podareanu, SURFsara, Netherlands
- Simon Portegies Zwart, Leiden Observatory, Netherlands 
- Qifan Pu, Google, USA
- Judy Qiu, Indiana University, USA
- Arvind Ramanathan, ANL, USA
- Vikram Saletore, Intel, USA
- Mikhail E. Smorkalov, Intel, Russia
- Rob Schreiber, Cerebras, USA
- Dan Stanzione, TACC, USA
- Rick Stevens, UChicago & ANL, USA
- Wei Tan, Citadel, USA
- Jordi Torres, Barcelona Supercomputing Center, Spain
- Daniela Ushizima, LBNL, USA
- Sofia Vallecorsa , CERN, Switzerland
- David Walling, TACC, USA
- Markus Weimer, Microsoft, USA
- Kathy Yelick, UC Berkeley & LBNL, USA
- Huazhe Zhang, Facebook, USA

### Previous Workshop
[1st Deep Learning on Supercomputers Workshop in SC'18 in Dallas, USA](https://www.tacc.utexas.edu/workshop/2018/deep-learning)

[2nd Deep Learning for Science Workshop in ISC'19 in Frankfurt, Germany](https://dlonsc.github.io/)
